{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222e5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c48d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset\n",
    "df = pd.read_csv('emotion-emotion_69k - emotion-emotion_69k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235bc80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Situation</th>\n",
       "      <th>emotion</th>\n",
       "      <th>empathetic_dialogues</th>\n",
       "      <th>labels</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :I remember going to see the firework...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :This was a best friend. I miss her.\\...</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Situation      emotion  \\\n",
       "0           0  I remember going to the fireworks with my best...  sentimental   \n",
       "1           1  I remember going to the fireworks with my best...  sentimental   \n",
       "\n",
       "                                empathetic_dialogues  \\\n",
       "0  Customer :I remember going to see the firework...   \n",
       "1  Customer :This was a best friend. I miss her.\\...   \n",
       "\n",
       "                                              labels Unnamed: 5 Unnamed: 6  \n",
       "0  Was this a friend you were in love with, or ju...        NaN        NaN  \n",
       "1                                Where has she gone?        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14e41be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64636, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb497ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  0\n",
       "Situation                   0\n",
       "emotion                     5\n",
       "empathetic_dialogues        5\n",
       "labels                      0\n",
       "Unnamed: 5              64554\n",
       "Unnamed: 6              64631\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b4ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0', 'Unnamed: 5', 'Unnamed: 6'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9feb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debdbddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Situation               0\n",
       "emotion                 0\n",
       "empathetic_dialogues    0\n",
       "labels                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c340364",
   "metadata": {},
   "source": [
    "### Removal of single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff65e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_word_remove_func(text, word_2_remove):\n",
    "    '''\n",
    "    Removes a specific word from string, if present\n",
    "    \n",
    "    Step 1: Use word_tokenize() to get tokens from string\n",
    "    Step 2: Removes the defined word from the created tokens\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the functions are to be applied, string\n",
    "        word_2_remove (str): Word to be removed from the text, string\n",
    "    \n",
    "    Returns:\n",
    "        String with removed words\n",
    "    '''    \n",
    "    word_to_remove = word_2_remove\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    text = ' '.join([word for word in words if word != word_to_remove])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ab7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "df['empathetic_dialogues'] = df['empathetic_dialogues'].apply(lambda x: single_word_remove_func(x, \"Customer :\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba7759b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Situation</th>\n",
       "      <th>emotion</th>\n",
       "      <th>empathetic_dialogues</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer : I remember going to see the firewor...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer : This was a best friend . I miss her...</td>\n",
       "      <td>Where has she gone?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Situation      emotion  \\\n",
       "0  I remember going to the fireworks with my best...  sentimental   \n",
       "1  I remember going to the fireworks with my best...  sentimental   \n",
       "\n",
       "                                empathetic_dialogues  \\\n",
       "0  Customer : I remember going to see the firewor...   \n",
       "1  Customer : This was a best friend . I miss her...   \n",
       "\n",
       "                                              labels  \n",
       "0  Was this a friend you were in love with, or ju...  \n",
       "1                                Where has she gone?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa1e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a start and end token to each answer\n",
    "df['Question Length'] = df['empathetic_dialogues'].str.split().apply(len)\n",
    "df['Answer Length'] = df['labels'].str.split().apply(len)\n",
    "df['Answers'] = df['labels'].apply(lambda x : '<start> '+ x + ' <end>')\n",
    "df['QA'] = df['empathetic_dialogues'].astype(str) + ' ' + df['Answers'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d756503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb444b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the dataset\n",
    "enc_in_train, enc_in_test, qa_train, qa_test, dec_in_train, dec_in_test = \\\n",
    "  train_test_split(df['empathetic_dialogues'], df['QA'], df['Answers'], test_size=0.005, random_state=42)\n",
    "\n",
    "enc_in_train, enc_in_val, qa_train, qa_val, dec_in_train, dec_in_val = \\\n",
    "  train_test_split( enc_in_train, qa_train, dec_in_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c574aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d52a5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the text sequences\n",
    "def create_tokenizer(lines):\n",
    "    \"\"\"\n",
    "    Fit a tokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1f17c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tokenizer = create_tokenizer(df['QA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f9afc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode and pad the text sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    \"\"\"\n",
    "    Encode and pad sequences\n",
    "    \"\"\"\n",
    "    # Integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # Pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "931a7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max length\n",
    "ques_length = df['Question Length'].max()\n",
    "ans_length = df['Answer Length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24ed483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_in_train = encode_sequences(qa_tokenizer, ques_length, enc_in_train)\n",
    "enc_in_val = encode_sequences(qa_tokenizer, ques_length, enc_in_val)\n",
    "enc_in_test = encode_sequences(qa_tokenizer, ques_length, enc_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a74b27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_in_train = encode_sequences(qa_tokenizer, ans_length+2, dec_in_train)\n",
    "dec_in_val = encode_sequences(qa_tokenizer, ans_length+2, dec_in_val)\n",
    "dec_in_test = encode_sequences(qa_tokenizer, ans_length+2, dec_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e1389cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20a2f902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 100.0% 1662.7/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "## Load pretrained Word2Vec word embeddings\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d08c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create lookup maps\n",
    "qa_vocab = qa_tokenizer.word_index\n",
    "word2id = dict()\n",
    "id2word = dict()\n",
    "for k, v in qa_vocab.items():\n",
    "    word2id[k] = v\n",
    "    id2word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40cff8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zeros' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Generate word embeddings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# create token-embedding mapping\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m embedding_matrix \u001b[38;5;241m=\u001b[39m zeros((\u001b[38;5;28mlen\u001b[39m(qa_vocab) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m300\u001b[39m))  \u001b[38;5;66;03m# Add 1 to account for the padding token\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, i \u001b[38;5;129;01min\u001b[39;00m qa_vocab\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word2vec_model:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zeros' is not defined"
     ]
    }
   ],
   "source": [
    "## Generate word embeddings\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = zeros((len(qa_vocab) + 1, 300))  # Add 1 to account for the padding token\n",
    "for word, i in qa_vocab.items():\n",
    "    if word in word2vec_model:\n",
    "        embedding_matrix[i] = word2vec_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051c518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
